# Software-Development-and-Scripting-Languages
# Теория 6 рукопожатий на Википедии

Данный проект реализует скрипт на языке Python для исследования "теории шести рукопожатий" в контексте статей Википедии. Целью является нахождение кратчайшей цепочки переходов (последовательности гиперссылок) между двумя заданными статьями Википедии, с учетом ограничений по глубине поиска и интенсивности запросов.

Основу алгоритма составляет поиск в ширину (BFS) (англ. Breadth-First Search). **BFS** — это алгоритм обхода графа, который систематически исследует узлы (в данном случае, статьи Википедии) уровень за уровнем.

Начиная с заданного стартового узла, BFS последовательно посещает всех его непосредственных соседей (статьи, на которые есть прямые ссылки), прежде чем перейти к узлам следующего уровня глубины. Такой поуровневый подход гарантирует, что все узлы на определённой глубине будут обработаны до того, как начнётся исследование более глубоких уровней.

Преимущества BFS для данной задачи:

* **Гарантия кратчайшего пути:** При первом обнаружении целевого узла BFS всегда находит кратчайший маршрут по числу рёбер (переходов). Это свойство критически важно для проверки "теории шести рукопожатий", где требуется найти минимальную последовательность связей.

* **Систематичность:** Поуровневый обход делает BFS надёжным методом для исчерпывающего, но при этом эффективного исследования сложных сетей, таких как граф статей Википедии.

## Ограничения
Для обеспечения корректной и эффективной работы скрипта предусмотрены следующие ограничения:
* **Язык статей:** Обе входные ссылки должны быть на одном языке, и скрипт будет искать переходы только на статьи на том же языке.
* **Источники ссылок:** Учитываются только ссылки из основного тела статьи или из блока "References". Принимаются только внутренние ссылки Википедии.
* **Rate-Limit:** Реализовано ограничение скорости запросов, чтобы не перегружать сервер Википедии.
* **Глубина поиска:** Поиск ограничен 5 переходами. Если путь не найден за 5 шагов, сообщается об этом. Избегается обработка дубликатов статей.

## Установка

Для развертывания и запуска скрипта требуется наличие Python 3.x и следующих внешних библиотек:

1.  **Клонируйте репозиторий:**
    ```bash
    git clone [https://github.com/your-username/wikipedia-six-degrees.git](https://github.com/your-username/wikipedia-six-degrees.git)
    cd wikipedia-six-degrees
    ```
    (Замените `your-username` на имя вашего пользователя GitHub)

2.  **Установите зависимости:**
    ```bash
    pip install requests beautifulsoup4
    ```

## Запуск

Запустите скрипт из командной строки, передав два URL-адреса статей Википедии и максимальное количество запросов в секунду (rate limit).

```bash
python wikipedia_six_degrees.py <url1> <url2> <rate_limit>
```

**Описание аргументов:**

* `<url1>`: Полный URL-адрес первой (стартовой) статьи Википедии.
* `<url2>`: Полный URL-адрес второй (целевой) статьи Википедии.
* `<rate_limit>`: Целое положительное число, задающее максимально допустимое количество HTTP-запросов к Википедии в секунду. Рекомендуемое значение: `10`.


```bash
Пример:
python wikipedia_six_degrees.py [https://en.wikipedia.org/wiki/Six_degrees_of_separation](https://en.wikipedia.org/wiki/Six_degrees_of_separation) [https://en.wikipedia.org/wiki/American_Broadcasting_Company](https://en.wikipedia.org/wiki/American_Broadcasting_Company) 10
